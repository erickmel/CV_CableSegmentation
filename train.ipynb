{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32ac979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install detectron2 -> Uncomment when connecting to Colab Kernel\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e824eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.9 ; cuda:  cu126\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "#!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b740bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.utils.logger import setup_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aedae01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.registerCable import register_cable\n",
    "from utils.customMapper import CableDatasetMapper\n",
    "from model.meta_arch import CableRCNN\n",
    "\n",
    "register_cable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321b40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data augmentation\n",
    "from detectron2.data import transforms as T\n",
    "# Define a sequence of augmentations:\n",
    "augs = [\n",
    "    T.RandomBrightness(0.9, 1.1),\n",
    "    T.RandomFlip(prob=0.5),\n",
    "    T.RandomCrop(\"absolute\", (700, 700)),\n",
    "    T.RandomRotation(angle=[-10, 10]),\n",
    "    T.RandomBrightness(0.8, 1.2),\n",
    "    T.RandomContrast(0.8, 1.2),\n",
    "    T.RandomSaturation(0.8, 1.2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd2c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        mapper = CableDatasetMapper(\n",
    "            cfg,\n",
    "            is_train=True,\n",
    "            augmentations=augs,  # your existing augmentations\n",
    "        )\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09386d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "\n",
    "def setup_cfg(config_file, overrides=None):\n",
    "    cfg = get_cfg()\n",
    "\n",
    "    cfg.MODEL.LINE_LOSS_WEIGHT = 0.0\n",
    "\n",
    "    cfg.merge_from_file(config_file)\n",
    "\n",
    "    if overrides:\n",
    "        cfg.merge_from_list(overrides)\n",
    "\n",
    "    cfg.freeze()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb87505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config 'model/maskrcnn_cable.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/cable\n"
     ]
    }
   ],
   "source": [
    "cfg = setup_cfg(\n",
    "    \"model/maskrcnn_cable.yaml\",\n",
    "    overrides=[\n",
    "        \"MODEL.LINE_LOSS_WEIGHT\", \"0.0\",\n",
    "        \"SOLVER.MAX_ITER\", \"40000\",\n",
    "        \"OUTPUT_DIR\", \"output/cable\",\n",
    "    ],\n",
    ")\n",
    "setup_logger()\n",
    "print(cfg.OUTPUT_DIR)\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b49c68e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mMyTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/detectron2/engine/defaults.py:410\u001b[39m, in \u001b[36mDefaultTrainer.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m    407\u001b[39m cfg = DefaultTrainer.auto_scale_workers(cfg, comm.get_world_size())\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Assume these objects must be constructed in this order.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m optimizer = \u001b[38;5;28mself\u001b[39m.build_optimizer(cfg, model)\n\u001b[32m    412\u001b[39m data_loader = \u001b[38;5;28mself\u001b[39m.build_train_loader(cfg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/detectron2/engine/defaults.py:550\u001b[39m, in \u001b[36mDefaultTrainer.build_model\u001b[39m\u001b[34m(cls, cfg)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, cfg):\n\u001b[32m    543\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    544\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m        torch.nn.Module:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    548\u001b[39m \u001b[33;03m    Overwrite it if you'd like a different model.\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     model = \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m    552\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mModel:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(model))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/detectron2/modeling/meta_arch/build.py:23\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     21\u001b[39m meta_arch = cfg.MODEL.META_ARCHITECTURE\n\u001b[32m     22\u001b[39m model = META_ARCH_REGISTRY.get(meta_arch)(cfg)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m _log_api_usage(\u001b[33m\"\u001b[39m\u001b[33mmodeling.meta_arch.\u001b[39m\u001b[33m\"\u001b[39m + meta_arch)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 930 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1022\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffers.items():\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m         \u001b[38;5;28mself\u001b[39m._buffers[key] = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ComputerVision/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:410\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    414\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b16e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
